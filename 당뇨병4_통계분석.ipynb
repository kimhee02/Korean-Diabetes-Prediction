{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f28b3f74-b5e9-4a45-8eb8-6fe78d3ba411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a6e2fb5-cf17-4791-9e35-0aaf2b7ce61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "male_df = pd.read_csv(\"C:/Users/JEONGHEE/Desktop/당뇨병플젝/male.csv\")\n",
    "female_df = pd.read_csv(\"C:/Users/JEONGHEE/Desktop/당뇨병플젝/female.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7eefe0b-82be-4ae8-a53a-2786e2a4c378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.628057\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   No. Observations:                 2571\n",
      "Model:                          Logit   Df Residuals:                     2551\n",
      "Method:                           MLE   Df Model:                           19\n",
      "Date:                Mon, 21 Apr 2025   Pseudo R-squ.:                 0.09390\n",
      "Time:                        01:58:29   Log-Likelihood:                -1614.7\n",
      "converged:                       True   LL-Null:                       -1782.1\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.476e-59\n",
      "=================================================================================\n",
      "                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "const            -0.0015      0.042     -0.036      0.971      -0.084       0.081\n",
      "DS1_AGE           0.1391      0.053      2.641      0.008       0.036       0.242\n",
      "DS1_HTN           0.0605      0.045      1.348      0.178      -0.027       0.148\n",
      "DS1_FDM           0.3027      0.044      6.902      0.000       0.217       0.389\n",
      "DS1_EXER         -0.0502      0.057     -0.889      0.374      -0.161       0.061\n",
      "DS1_WALKFQ        0.0620      0.043      1.431      0.153      -0.023       0.147\n",
      "DS1_HIP          -0.1047      0.079     -1.332      0.183      -0.259       0.049\n",
      "DS1_PULSE         0.3131      0.045      6.990      0.000       0.225       0.401\n",
      "DS1_SBP           0.2662      0.067      3.992      0.000       0.135       0.397\n",
      "DS1_DBP          -0.0604      0.064     -0.937      0.349      -0.187       0.066\n",
      "DS1_BMI           0.1322      0.102      1.293      0.196      -0.068       0.333\n",
      "DS1_PBF           0.0650      0.126      0.515      0.606      -0.182       0.312\n",
      "DS1_MUSCLE       -0.1064      0.080     -1.332      0.183      -0.263       0.050\n",
      "DS1_VISFAT        0.2324      0.133      1.753      0.080      -0.027       0.492\n",
      "DS1_WHR           0.2325      0.059      3.966      0.000       0.118       0.347\n",
      "DS1_INCOME_RE     0.0704      0.049      1.433      0.152      -0.026       0.167\n",
      "DS1_EDU_RE       -0.0891      0.049     -1.824      0.068      -0.185       0.007\n",
      "total_exer        0.0473      0.054      0.875      0.381      -0.059       0.153\n",
      "DS1_SMOKE_RE      0.1425      0.044      3.258      0.001       0.057       0.228\n",
      "DS1_DRINK_RE     -0.0230      0.044     -0.528      0.598      -0.108       0.062\n",
      "=================================================================================\n",
      "\n",
      "Classification Report (Test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.72      0.71       322\n",
      "           1       0.71      0.67      0.69       321\n",
      "\n",
      "    accuracy                           0.70       643\n",
      "   macro avg       0.70      0.70      0.70       643\n",
      "weighted avg       0.70      0.70      0.70       643\n",
      "\n",
      "AUC: 0.773\n",
      "\n",
      "Confusion Matrix:\n",
      "[[233  89]\n",
      " [105 216]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "from sklearn.utils import resample\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "basic_drop_cols = ['DS1_ID', 'DS1_SEX', 'DS1_GLU0', 'DS1_HBA1C',\n",
    "             'DS1_WALK', 'DS1_WALKT', 'DS1_WAIST', 'DS1_BODYFAT', 'DS1_MARRY_RE'] \n",
    "X = male_df.drop(columns=basic_drop_cols + ['target'])\n",
    "y = male_df['target']\n",
    "\n",
    "\n",
    "df_all = X.copy()\n",
    "df_all['target'] = y\n",
    "df_majority = df_all[df_all['target'] == 0]\n",
    "df_minority = df_all[df_all['target'] == 1]\n",
    "df_majority_down = resample(df_majority, replace=False, n_samples=len(df_minority), random_state=42)\n",
    "df_balanced = pd.concat([df_majority_down, df_minority])\n",
    "X_bal = df_balanced.drop(columns=['target'])\n",
    "y_bal = df_balanced['target']\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X_bal), columns=X_bal.columns, index=X_bal.index)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_bal, test_size=0.2, stratify=y_bal, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "X_train_const = sm.add_constant(X_train)\n",
    "logit_model = sm.Logit(y_train, X_train_const)\n",
    "result = logit_model.fit()\n",
    "\n",
    "\n",
    "print(result.summary())\n",
    "\n",
    "X_test_const = sm.add_constant(X_test)\n",
    "X_test_const = X_test_const[X_train_const.columns]  # ensure same columns order\n",
    "\n",
    "y_pred_prob = result.predict(X_test_const)\n",
    "y_pred_label = (y_pred_prob >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\nClassification Report (Test):\")\n",
    "print(classification_report(y_test, y_pred_label))\n",
    "print(\"AUC:\", round(roc_auc_score(y_test, y_pred_prob), 3))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46af137a-f8b1-4857-b1fc-14fdcff0fe5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.628057\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   No. Observations:                 2571\n",
      "Model:                          Logit   Df Residuals:                     2551\n",
      "Method:                           MLE   Df Model:                           19\n",
      "Date:                Mon, 21 Apr 2025   Pseudo R-squ.:                 0.09390\n",
      "Time:                        01:58:30   Log-Likelihood:                -1614.7\n",
      "converged:                       True   LL-Null:                       -1782.1\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.476e-59\n",
      "=================================================================================\n",
      "                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "const            -0.0015      0.042     -0.036      0.971      -0.084       0.081\n",
      "DS1_AGE           0.1391      0.053      2.641      0.008       0.036       0.242\n",
      "DS1_HTN           0.0605      0.045      1.348      0.178      -0.027       0.148\n",
      "DS1_FDM           0.3027      0.044      6.902      0.000       0.217       0.389\n",
      "DS1_EXER         -0.0502      0.057     -0.889      0.374      -0.161       0.061\n",
      "DS1_WALKFQ        0.0620      0.043      1.431      0.153      -0.023       0.147\n",
      "DS1_HIP          -0.1047      0.079     -1.332      0.183      -0.259       0.049\n",
      "DS1_PULSE         0.3131      0.045      6.990      0.000       0.225       0.401\n",
      "DS1_SBP           0.2662      0.067      3.992      0.000       0.135       0.397\n",
      "DS1_DBP          -0.0604      0.064     -0.937      0.349      -0.187       0.066\n",
      "DS1_BMI           0.1322      0.102      1.293      0.196      -0.068       0.333\n",
      "DS1_PBF           0.0650      0.126      0.515      0.606      -0.182       0.312\n",
      "DS1_MUSCLE       -0.1064      0.080     -1.332      0.183      -0.263       0.050\n",
      "DS1_VISFAT        0.2324      0.133      1.753      0.080      -0.027       0.492\n",
      "DS1_WHR           0.2325      0.059      3.966      0.000       0.118       0.347\n",
      "DS1_INCOME_RE     0.0704      0.049      1.433      0.152      -0.026       0.167\n",
      "DS1_EDU_RE       -0.0891      0.049     -1.824      0.068      -0.185       0.007\n",
      "total_exer        0.0473      0.054      0.875      0.381      -0.059       0.153\n",
      "DS1_SMOKE_RE      0.1425      0.044      3.258      0.001       0.057       0.228\n",
      "DS1_DRINK_RE     -0.0230      0.044     -0.528      0.598      -0.108       0.062\n",
      "=================================================================================\n",
      "\n",
      "Classification Report (Test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.72      0.71       322\n",
      "           1       0.71      0.67      0.69       321\n",
      "\n",
      "    accuracy                           0.70       643\n",
      "   macro avg       0.70      0.70      0.70       643\n",
      "weighted avg       0.70      0.70      0.70       643\n",
      "\n",
      "AUC: 0.773\n",
      "\n",
      "Confusion Matrix:\n",
      "[[233  89]\n",
      " [105 216]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "from sklearn.utils import resample\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "\n",
    "basic_drop_cols = ['DS1_ID', 'DS1_SEX', 'DS1_GLU0', 'DS1_HBA1C',\n",
    "             'DS1_WALK', 'DS1_WALKT', 'DS1_WAIST', 'DS1_BODYFAT', 'DS1_MARRY_RE'] \n",
    "X = male_df.drop(columns=basic_drop_cols + ['target'])\n",
    "y = male_df['target']\n",
    "\n",
    "# 언더샘플링\n",
    "df_all = X.copy()\n",
    "df_all['target'] = y\n",
    "df_majority = df_all[df_all['target'] == 0]\n",
    "df_minority = df_all[df_all['target'] == 1]\n",
    "df_majority_down = resample(df_majority, replace=False, n_samples=len(df_minority), random_state=42)\n",
    "df_balanced = pd.concat([df_majority_down, df_minority])\n",
    "X_bal = df_balanced.drop(columns=['target'])\n",
    "y_bal = df_balanced['target']\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X_bal), columns=X_bal.columns, index=X_bal.index)\n",
    "\n",
    "\n",
    "def remove_high_vif(X, thresh=10.0):\n",
    "    variables = X.columns.tolist()\n",
    "    while True:\n",
    "        vif = [variance_inflation_factor(X[variables].values, i) for i in range(len(variables))]\n",
    "        max_vif = max(vif)\n",
    "        if max_vif > thresh:\n",
    "            max_index = vif.index(max_vif)\n",
    "            print(f\"제거된 변수: {variables[max_index]} (VIF: {max_vif:.2f})\")\n",
    "            variables.pop(max_index)\n",
    "        else:\n",
    "            break\n",
    "    return X[variables]\n",
    "\n",
    "X_vif = remove_high_vif(X_scaled, thresh=10.0)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_vif, y_bal, test_size=0.2, stratify=y_bal, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "X_train_const = sm.add_constant(X_train)\n",
    "logit_model = sm.Logit(y_train, X_train_const)\n",
    "result = logit_model.fit()\n",
    "print(result.summary())\n",
    "\n",
    "X_test_const = sm.add_constant(X_test)\n",
    "X_test_const = X_test_const[X_train_const.columns]  # ensure same columns order\n",
    "\n",
    "y_pred_prob = result.predict(X_test_const)\n",
    "y_pred_label = (y_pred_prob >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\nClassification Report (Test):\")\n",
    "print(classification_report(y_test, y_pred_label))\n",
    "print(\"AUC:\", round(roc_auc_score(y_test, y_pred_prob), 3))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613515ce-7ce3-41f5-841e-db5297ff5e36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9125021a-09f1-4abc-90a0-e51407ccd955",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dc0178-c56e-404c-9656-2e063ad2bbe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd8df27-0151-495a-9cf6-badbf438ae0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17c9241f-84ec-4535-b655-3647af96482e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제거된 변수: DS1_PBF (VIF: 6.86)\n",
      "제거된 변수: DS1_BMI (VIF: 5.13)\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.628538\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   No. Observations:                 2571\n",
      "Model:                          Logit   Df Residuals:                     2553\n",
      "Method:                           MLE   Df Model:                           17\n",
      "Date:                Mon, 21 Apr 2025   Pseudo R-squ.:                 0.09321\n",
      "Time:                        02:10:25   Log-Likelihood:                -1616.0\n",
      "converged:                       True   LL-Null:                       -1782.1\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.428e-60\n",
      "=================================================================================\n",
      "                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "const             0.0014      0.042      0.033      0.974      -0.081       0.084\n",
      "DS1_AGE           0.1332      0.052      2.540      0.011       0.030       0.236\n",
      "DS1_HTN           0.0636      0.045      1.419      0.156      -0.024       0.151\n",
      "DS1_FDM           0.3025      0.044      6.899      0.000       0.217       0.388\n",
      "DS1_EXER         -0.0506      0.057     -0.895      0.371      -0.161       0.060\n",
      "DS1_WALKFQ        0.0624      0.043      1.441      0.150      -0.022       0.147\n",
      "DS1_HIP          -0.0663      0.075     -0.888      0.375      -0.213       0.080\n",
      "DS1_PULSE         0.3092      0.045      6.933      0.000       0.222       0.397\n",
      "DS1_SBP           0.2691      0.067      4.037      0.000       0.138       0.400\n",
      "DS1_DBP          -0.0576      0.064     -0.894      0.371      -0.184       0.069\n",
      "DS1_MUSCLE       -0.0984      0.060     -1.630      0.103      -0.217       0.020\n",
      "DS1_VISFAT        0.3630      0.079      4.592      0.000       0.208       0.518\n",
      "DS1_WHR           0.2597      0.056      4.635      0.000       0.150       0.370\n",
      "DS1_INCOME_RE     0.0726      0.049      1.481      0.139      -0.023       0.169\n",
      "DS1_EDU_RE       -0.0935      0.049     -1.928      0.054      -0.189       0.002\n",
      "total_exer        0.0505      0.054      0.935      0.350      -0.055       0.156\n",
      "DS1_SMOKE_RE      0.1384      0.044      3.170      0.002       0.053       0.224\n",
      "DS1_DRINK_RE     -0.0223      0.044     -0.512      0.609      -0.108       0.063\n",
      "=================================================================================\n",
      "\n",
      "Classification Report (Test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.73      0.71       322\n",
      "           1       0.71      0.68      0.70       321\n",
      "\n",
      "    accuracy                           0.70       643\n",
      "   macro avg       0.70      0.70      0.70       643\n",
      "weighted avg       0.70      0.70      0.70       643\n",
      "\n",
      "AUC: 0.772\n",
      "\n",
      "Confusion Matrix:\n",
      "[[234  88]\n",
      " [102 219]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "from sklearn.utils import resample\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "\n",
    "basic_drop_cols = ['DS1_ID', 'DS1_SEX', 'DS1_GLU0', 'DS1_HBA1C',\n",
    "             'DS1_WALK', 'DS1_WALKT', 'DS1_WAIST', 'DS1_BODYFAT', 'DS1_MARRY_RE'] \n",
    "X = male_df.drop(columns=basic_drop_cols + ['target'])\n",
    "y = male_df['target']\n",
    "\n",
    "\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_resampled, y_resampled = undersampler.fit_resample(X, y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X_resampled), columns=X.columns, index=X_resampled.index)\n",
    "\n",
    "\n",
    "def remove_high_vif(X, thresh=5.0):\n",
    "    variables = X.columns.tolist()\n",
    "    while True:\n",
    "        vif = [variance_inflation_factor(X[variables].values, i) for i in range(len(variables))]\n",
    "        max_vif = max(vif)\n",
    "        if max_vif > thresh:\n",
    "            max_index = vif.index(max_vif)\n",
    "            print(f\"제거된 변수: {variables[max_index]} (VIF: {max_vif:.2f})\")\n",
    "            variables.pop(max_index)\n",
    "        else:\n",
    "            break\n",
    "    return X[variables]\n",
    "\n",
    "X_vif = remove_high_vif(X_scaled, thresh=5.0)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_vif, y_resampled, test_size=0.2, stratify=y_resampled, random_state=42\n",
    ")\n",
    "\n",
    "X_train_const = sm.add_constant(X_train)\n",
    "logit_model = sm.Logit(y_train, X_train_const)\n",
    "result = logit_model.fit()\n",
    "\n",
    "print(result.summary())\n",
    "\n",
    "X_test_const = sm.add_constant(X_test)\n",
    "X_test_const = X_test_const[X_train_const.columns]  # ensure same columns order\n",
    "\n",
    "y_pred_prob = result.predict(X_test_const)\n",
    "y_pred_label = (y_pred_prob >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\nClassification Report (Test):\")\n",
    "print(classification_report(y_test, y_pred_label))\n",
    "print(\"AUC:\", round(roc_auc_score(y_test, y_pred_prob), 3))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4791b8e-acbe-4740-ac69-09eef28267b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제거된 변수: DS1_PBF (VIF: 6.86)\n",
      "제거된 변수: DS1_BMI (VIF: 5.13)\n",
      "제거된 변수 (p > 0.05): DS1_DRINK_RE (0.6089)\n",
      "제거된 변수 (p > 0.05): DS1_HIP (0.3774)\n",
      "제거된 변수 (p > 0.05): DS1_EXER (0.3799)\n",
      "제거된 변수 (p > 0.05): total_exer (0.6313)\n",
      "제거된 변수 (p > 0.05): DS1_DBP (0.3682)\n",
      "제거된 변수 (p > 0.05): DS1_HTN (0.1716)\n",
      "제거된 변수 (p > 0.05): DS1_INCOME_RE (0.1481)\n",
      "제거된 변수 (p > 0.05): DS1_EDU_RE (0.1280)\n",
      "제거된 변수 (p > 0.05): DS1_WALKFQ (0.0727)\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   No. Observations:                 2571\n",
      "Model:                          Logit   Df Residuals:                     2562\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Mon, 21 Apr 2025   Pseudo R-squ.:                 0.08974\n",
      "Time:                        02:10:35   Log-Likelihood:                -1622.2\n",
      "converged:                       True   LL-Null:                       -1782.1\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.433e-64\n",
      "================================================================================\n",
      "                   coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "const            0.0003      0.042      0.008      0.994      -0.082       0.083\n",
      "DS1_AGE          0.1479      0.046      3.200      0.001       0.057       0.239\n",
      "DS1_FDM          0.3002      0.044      6.879      0.000       0.215       0.386\n",
      "DS1_PULSE        0.3119      0.044      7.072      0.000       0.225       0.398\n",
      "DS1_SBP          0.2367      0.045      5.250      0.000       0.148       0.325\n",
      "DS1_MUSCLE      -0.1215      0.052     -2.347      0.019      -0.223      -0.020\n",
      "DS1_VISFAT       0.3128      0.059      5.287      0.000       0.197       0.429\n",
      "DS1_WHR          0.2903      0.051      5.658      0.000       0.190       0.391\n",
      "DS1_SMOKE_RE     0.1407      0.043      3.283      0.001       0.057       0.225\n",
      "================================================================================\n",
      "\n",
      "Classification Report (Test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.72      0.70       322\n",
      "           1       0.70      0.67      0.69       321\n",
      "\n",
      "    accuracy                           0.70       643\n",
      "   macro avg       0.70      0.70      0.70       643\n",
      "weighted avg       0.70      0.70      0.70       643\n",
      "\n",
      "AUC: 0.767\n",
      "\n",
      "Confusion Matrix:\n",
      "[[231  91]\n",
      " [105 216]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "\n",
    "basic_drop_cols = ['DS1_ID', 'DS1_SEX', 'DS1_GLU0', 'DS1_HBA1C',\n",
    "             'DS1_WALK', 'DS1_WALKT', 'DS1_WAIST', 'DS1_BODYFAT', 'DS1_MARRY_RE'] \n",
    "X = male_df.drop(columns=basic_drop_cols + ['target'])\n",
    "y = male_df['target']\n",
    "\n",
    "\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_resampled, y_resampled = undersampler.fit_resample(X, y)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X_resampled), columns=X.columns, index=X_resampled.index)\n",
    "\n",
    "\n",
    "def remove_high_vif(X, thresh=5.0):\n",
    "    variables = X.columns.tolist()\n",
    "    while True:\n",
    "        vif = [variance_inflation_factor(X[variables].values, i) for i in range(len(variables))]\n",
    "        max_vif = max(vif)\n",
    "        if max_vif > thresh:\n",
    "            max_index = vif.index(max_vif)\n",
    "            print(f\"제거된 변수: {variables[max_index]} (VIF: {max_vif:.2f})\")\n",
    "            variables.pop(max_index)\n",
    "        else:\n",
    "            break\n",
    "    return X[variables]\n",
    "\n",
    "X_vif = remove_high_vif(X_scaled, thresh=5.0)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_vif, y_resampled, test_size=0.2, stratify=y_resampled, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "def fit_logit_and_filter(X, y, p_thresh=0.05):\n",
    "    X_const = sm.add_constant(X)\n",
    "    model = sm.Logit(y, X_const).fit(disp=0)\n",
    "    while True:\n",
    "        pvalues = model.pvalues.drop('const', errors='ignore')\n",
    "        max_pval = pvalues.max()\n",
    "        if max_pval > p_thresh:\n",
    "            worst_feature = pvalues.idxmax()\n",
    "            print(f\"제거된 변수 (p > {p_thresh}): {worst_feature} ({max_pval:.4f})\")\n",
    "            X = X.drop(columns=[worst_feature])\n",
    "            X_const = sm.add_constant(X)\n",
    "            model = sm.Logit(y, X_const).fit(disp=0)\n",
    "        else:\n",
    "            break\n",
    "    return model, X\n",
    "\n",
    "result, X_train_final = fit_logit_and_filter(X_train, y_train)\n",
    "\n",
    "\n",
    "print(result.summary())\n",
    "\n",
    "\n",
    "X_test_final = X_test[X_train_final.columns]\n",
    "X_test_const = sm.add_constant(X_test_final)\n",
    "\n",
    "y_pred_prob = result.predict(X_test_const)\n",
    "y_pred_label = (y_pred_prob >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\nClassification Report (Test):\")\n",
    "print(classification_report(y_test, y_pred_label))\n",
    "print(\"AUC:\", round(roc_auc_score(y_test, y_pred_prob), 3))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1621b4-73f7-4f90-af91-7728f332bcc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
